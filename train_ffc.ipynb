{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf078a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # noqa: N812\n",
    "from omegaconf import OmegaConf\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from datasets import load_cifar10\n",
    "from models import BaseModel, FFCBlock\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd20bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(BaseModel):\n",
    "    train_keys = (\"loss\",)\n",
    "    val_keys = (\"loss\", \"acc\")\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.layer = nn.Sequential(\n",
    "            FFCBlock(\n",
    "                16,\n",
    "                16,\n",
    "                16,\n",
    "                ratio_in=(1.0, 0.0),\n",
    "                ratio_out=(0.5, 0.5),\n",
    "                stride=2,\n",
    "                enable_lfu=True,\n",
    "            ),\n",
    "            FFCBlock(\n",
    "                16,\n",
    "                16,\n",
    "                16,\n",
    "                ratio_in=(0.5, 0.5),\n",
    "                ratio_out=(0.5, 0.5),\n",
    "                stride=2,\n",
    "                enable_lfu=True,\n",
    "            ),\n",
    "            FFCBlock(\n",
    "                16,\n",
    "                16,\n",
    "                16,\n",
    "                ratio_in=(0.5, 0.5),\n",
    "                ratio_out=(1.0, 0.0),\n",
    "                stride=2,\n",
    "                enable_lfu=True,\n",
    "            ),\n",
    "        )\n",
    "        self.layer_final = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "        return\n",
    "\n",
    "    def get_output(self, x: Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x, _ = self.layer(x)  # (-1 x 256 x 4 x 4)\n",
    "        x = self.layer_final(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor, target: Tensor):\n",
    "        output = self.get_output(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        return dict(loss=loss)\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def validate_batch(self, x: Tensor, target: Tensor):\n",
    "        output = self.get_output(x)\n",
    "        loss = F.cross_entropy(output, target).item()\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        acc = target.eq(pred).float()\n",
    "        acc = acc.mean().item()\n",
    "\n",
    "        return dict(loss=loss, acc=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63611017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_cifar10(root=\"./data\", kind=\"train\")\n",
    "val_set = load_cifar10(root=\"./data\", kind=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173496a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"./configs/simple_ffc.yaml\")\n",
    "model = CustomModel().to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8983e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  0: 100%|██████████| 313/313 [00:13<00:00, 23.32it/s, train/loss=2.296, val/loss=2.213, val/acc=0.169]\n",
      "Epoch  1: 100%|██████████| 313/313 [00:13<00:00, 23.43it/s, train/loss=2.119, val/loss=2.084, val/acc=0.215]\n",
      "Epoch  2: 100%|██████████| 313/313 [00:13<00:00, 22.97it/s, train/loss=2.010, val/loss=1.989, val/acc=0.256]\n",
      "Epoch  3: 100%|██████████| 313/313 [00:12<00:00, 24.10it/s, train/loss=1.923, val/loss=1.909, val/acc=0.288]\n",
      "Epoch  4: 100%|██████████| 313/313 [00:12<00:00, 25.60it/s, train/loss=1.851, val/loss=1.845, val/acc=0.309]\n",
      "Epoch  5: 100%|██████████| 313/313 [00:12<00:00, 25.34it/s, train/loss=1.799, val/loss=1.802, val/acc=0.327]\n",
      "Epoch  6: 100%|██████████| 313/313 [00:12<00:00, 24.75it/s, train/loss=1.758, val/loss=1.762, val/acc=0.344]\n",
      "Epoch  7: 100%|██████████| 313/313 [00:12<00:00, 24.30it/s, train/loss=1.721, val/loss=1.724, val/acc=0.353]\n",
      "Epoch  8: 100%|██████████| 313/313 [00:12<00:00, 25.57it/s, train/loss=1.686, val/loss=1.691, val/acc=0.364]\n",
      "Epoch  9: 100%|██████████| 313/313 [00:12<00:00, 24.98it/s, train/loss=1.659, val/loss=1.665, val/acc=0.377]\n",
      "Epoch 10: 100%|██████████| 313/313 [00:13<00:00, 23.41it/s, train/loss=1.637, val/loss=1.640, val/acc=0.383]\n",
      "Epoch 11: 100%|██████████| 313/313 [00:12<00:00, 25.39it/s, train/loss=1.613, val/loss=1.623, val/acc=0.395]\n",
      "Epoch 12: 100%|██████████| 313/313 [00:12<00:00, 24.60it/s, train/loss=1.596, val/loss=1.605, val/acc=0.405]\n",
      "Epoch 13: 100%|██████████| 313/313 [00:13<00:00, 24.02it/s, train/loss=1.579, val/loss=1.588, val/acc=0.412]\n",
      "Epoch 14: 100%|██████████| 313/313 [00:12<00:00, 25.50it/s, train/loss=1.564, val/loss=1.574, val/acc=0.417]\n",
      "Epoch 15: 100%|██████████| 313/313 [00:12<00:00, 25.39it/s, train/loss=1.553, val/loss=1.559, val/acc=0.423]\n",
      "Epoch 16: 100%|██████████| 313/313 [00:12<00:00, 24.30it/s, train/loss=1.540, val/loss=1.547, val/acc=0.428]\n",
      "Epoch 17: 100%|██████████| 313/313 [00:13<00:00, 23.77it/s, train/loss=1.525, val/loss=1.539, val/acc=0.431]\n",
      "Epoch 18: 100%|██████████| 313/313 [00:13<00:00, 24.02it/s, train/loss=1.515, val/loss=1.527, val/acc=0.435]\n",
      "Epoch 19: 100%|██████████| 313/313 [00:12<00:00, 25.22it/s, train/loss=1.505, val/loss=1.515, val/acc=0.442]\n",
      "Epoch 20: 100%|██████████| 313/313 [00:12<00:00, 25.33it/s, train/loss=1.488, val/loss=1.501, val/acc=0.446]\n",
      "Epoch 21: 100%|██████████| 313/313 [00:12<00:00, 24.17it/s, train/loss=1.484, val/loss=1.490, val/acc=0.452]\n",
      "Epoch 22: 100%|██████████| 313/313 [00:13<00:00, 23.25it/s, train/loss=1.476, val/loss=1.485, val/acc=0.456]\n",
      "Epoch 23: 100%|██████████| 313/313 [00:12<00:00, 25.28it/s, train/loss=1.468, val/loss=1.473, val/acc=0.463]\n",
      "Epoch 24: 100%|██████████| 313/313 [00:12<00:00, 25.42it/s, train/loss=1.453, val/loss=1.464, val/acc=0.464]\n",
      "Epoch 25: 100%|██████████| 313/313 [00:12<00:00, 24.85it/s, train/loss=1.445, val/loss=1.456, val/acc=0.464]\n",
      "Epoch 26: 100%|██████████| 313/313 [00:12<00:00, 25.08it/s, train/loss=1.437, val/loss=1.452, val/acc=0.469]\n",
      "Epoch 27: 100%|██████████| 313/313 [00:12<00:00, 25.30it/s, train/loss=1.429, val/loss=1.442, val/acc=0.471]\n",
      "Epoch 28: 100%|██████████| 313/313 [00:12<00:00, 25.27it/s, train/loss=1.423, val/loss=1.437, val/acc=0.473]\n",
      "Epoch 29: 100%|██████████| 313/313 [00:12<00:00, 25.32it/s, train/loss=1.416, val/loss=1.429, val/acc=0.473]\n",
      "Epoch 30: 100%|██████████| 313/313 [00:12<00:00, 25.30it/s, train/loss=1.411, val/loss=1.423, val/acc=0.475]\n",
      "Epoch 31: 100%|██████████| 313/313 [00:12<00:00, 25.54it/s, train/loss=1.400, val/loss=1.416, val/acc=0.479]\n",
      "Epoch 32: 100%|██████████| 313/313 [00:12<00:00, 25.14it/s, train/loss=1.395, val/loss=1.410, val/acc=0.486]\n",
      "Epoch 33: 100%|██████████| 313/313 [00:12<00:00, 25.59it/s, train/loss=1.383, val/loss=1.403, val/acc=0.491]\n",
      "Epoch 34: 100%|██████████| 313/313 [00:12<00:00, 25.24it/s, train/loss=1.380, val/loss=1.398, val/acc=0.486]\n",
      "Epoch 35: 100%|██████████| 313/313 [00:12<00:00, 25.12it/s, train/loss=1.378, val/loss=1.394, val/acc=0.491]\n",
      "Epoch 36: 100%|██████████| 313/313 [00:13<00:00, 22.56it/s, train/loss=1.370, val/loss=1.391, val/acc=0.493]\n",
      "Epoch 37: 100%|██████████| 313/313 [00:13<00:00, 22.74it/s, train/loss=1.361, val/loss=1.382, val/acc=0.493]\n",
      "Epoch 38: 100%|██████████| 313/313 [00:13<00:00, 23.56it/s, train/loss=1.356, val/loss=1.377, val/acc=0.496]\n",
      "Epoch 39: 100%|██████████| 313/313 [00:13<00:00, 23.23it/s, train/loss=1.352, val/loss=1.373, val/acc=0.501]\n",
      "Epoch 40: 100%|██████████| 313/313 [00:13<00:00, 23.76it/s, train/loss=1.347, val/loss=1.380, val/acc=0.492]\n",
      "Epoch 41: 100%|██████████| 313/313 [00:13<00:00, 23.33it/s, train/loss=1.338, val/loss=1.360, val/acc=0.500]\n",
      "Epoch 42: 100%|██████████| 313/313 [00:12<00:00, 24.28it/s, train/loss=1.334, val/loss=1.355, val/acc=0.504]\n",
      "Epoch 43: 100%|██████████| 313/313 [00:13<00:00, 24.03it/s, train/loss=1.336, val/loss=1.350, val/acc=0.506]\n",
      "Epoch 44: 100%|██████████| 313/313 [00:13<00:00, 23.25it/s, train/loss=1.322, val/loss=1.346, val/acc=0.510]\n",
      "Epoch 45: 100%|██████████| 313/313 [00:13<00:00, 24.05it/s, train/loss=1.321, val/loss=1.339, val/acc=0.512]\n",
      "Epoch 46: 100%|██████████| 313/313 [00:12<00:00, 24.74it/s, train/loss=1.316, val/loss=1.338, val/acc=0.512]\n",
      "Epoch 47: 100%|██████████| 313/313 [00:12<00:00, 24.76it/s, train/loss=1.302, val/loss=1.333, val/acc=0.513]\n",
      "Epoch 48: 100%|██████████| 313/313 [00:12<00:00, 26.05it/s, train/loss=1.304, val/loss=1.329, val/acc=0.515]\n",
      "Epoch 49: 100%|██████████| 313/313 [00:12<00:00, 25.31it/s, train/loss=1.297, val/loss=1.322, val/acc=0.518]\n",
      "Epoch 50: 100%|██████████| 313/313 [00:12<00:00, 25.47it/s, train/loss=1.296, val/loss=1.320, val/acc=0.518]\n",
      "Epoch 51: 100%|██████████| 313/313 [00:12<00:00, 25.23it/s, train/loss=1.286, val/loss=1.317, val/acc=0.520]\n",
      "Epoch 52: 100%|██████████| 313/313 [00:12<00:00, 25.94it/s, train/loss=1.281, val/loss=1.311, val/acc=0.522]\n",
      "Epoch 53: 100%|██████████| 313/313 [00:12<00:00, 25.62it/s, train/loss=1.282, val/loss=1.306, val/acc=0.529]\n",
      "Epoch 54: 100%|██████████| 313/313 [00:12<00:00, 25.52it/s, train/loss=1.279, val/loss=1.308, val/acc=0.525]\n",
      "Epoch 55: 100%|██████████| 313/313 [00:12<00:00, 25.58it/s, train/loss=1.274, val/loss=1.298, val/acc=0.531]\n",
      "Epoch 56: 100%|██████████| 313/313 [00:12<00:00, 25.63it/s, train/loss=1.267, val/loss=1.297, val/acc=0.533]\n",
      "Epoch 57:  87%|████████▋ | 271/313 [00:09<00:01, 29.62it/s, loss=1.26]"
     ]
    }
   ],
   "source": [
    "train(model, config, train_set, val_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
